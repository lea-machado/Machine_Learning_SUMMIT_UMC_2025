# An√°lise Comparativa de M√©todos de Valida√ß√£o Cruzada no Desempenho do Classificador SVM para Predi√ß√£o de Doen√ßas Card√≠acas

## 1. üéØ Objetivo do Projeto

[cite_start]Este reposit√≥rio documenta uma an√°lise sobre a aplica√ß√£o do modelo de aprendizado de m√°quina **M√°quina de Vetores de Suporte (SVM)** para a predi√ß√£o de doen√ßas card√≠acas[cite: 4]. [cite_start]O foco principal do estudo √© uma an√°lise comparativa rigorosa de como diferentes estrat√©gias de valida√ß√£o cruzada (CV) ‚Äî especificamente **KFold** e **StratifiedShuffleSplit** ‚Äî impactam a performance estimada e a sele√ß√£o de hiperpar√¢metros do classificador[cite: 6, 7].

[cite_start]A escolha do m√©todo de valida√ß√£o √© fundamental na √°rea biom√©dica para estimar a capacidade de generaliza√ß√£o do modelo, prevenir o superajuste (overfitting) [cite: 5] [cite_start]e garantir a confiabilidade dos resultados[cite: 4].

## 2. üíæ Dataset

[cite_start]O estudo utilizou o dataset "Heart Disease (Cleveland)"[cite: 7], obtido de um reposit√≥rio p√∫blico. Este conjunto de dados cont√©m 303 amostras (pacientes) e 13 atributos cl√≠nicos (features), como idade, sexo, tipo de dor no peito (`cp`) e n√∫mero de vasos principais (`ca`).

O atributo alvo (`target`) √© uma classifica√ß√£o bin√°ria:
* **0:** Saud√°vel (sem doen√ßa card√≠aca)
* **1:** Doente (presen√ßa de doen√ßa card√≠aca)

## 3. üõ†Ô∏è Metodologia e Pipeline do Modelo

[cite_start]Para garantir a reprodutibilidade e evitar o vazamento de dados (*data leakage*), todo o processo de pr√©-processamento e modelagem foi encapsulado em um `Pipeline` do Scikit-learn[cite: 8].

O pipeline de classifica√ß√£o consiste nas seguintes etapas:

1.  [cite_start]**Pr√©-processamento (`StandardScaler`):** Padroniza√ß√£o dos atributos num√©ricos (Z-score) para normalizar a escala das *features* antes de alimentar o modelo SVM[cite: 8].
2.  **Classifica√ß√£o (`SVC`):** Utiliza√ß√£o do Classificador de Vetores de Suporte (Support Vector Classifier) como o estimador principal.
3.  [cite_start]**Otimiza√ß√£o (`GridSearchCV`):** O `GridSearchCV` foi empregado para realizar uma busca exaustiva (grid search) e encontrar a combina√ß√£o √≥tima de hiperpar√¢metros (`C`, `kernel` e `gamma`) para o SVC[cite: 9].

## 4. üìä An√°lise Central: KFold vs. StratifiedShuffleSplit

O `GridSearchCV` foi executado duas vezes, aplicando duas estrat√©gias de CV distintas para avaliar o pipeline:

* [cite_start]**KFold (KFold-10):** Uma CV padr√£o com 10 parti√ß√µes (folds) sequenciais[cite: 7].
* [cite_start]**StratifiedShuffleSplit (SSS):** Uma CV com 10 divis√µes, utilizando 25% dos dados para teste em cada divis√£o[cite: 7]. [cite_start]Crucialmente, o SSS garante que a propor√ß√£o das classes (saud√°vel vs. doente) seja mantida em cada conjunto de treino e teste (estratifica√ß√£o)[cite: 14, 32].

## 5. üìà Resultados e Visualiza√ß√µes

A an√°lise comparativa revelou nuances importantes no desempenho de cada estrat√©gia, conforme detalhado no notebook `SVC_Doencas_Cardiacas.ipynb`.

### Tabela Comparativa dos Melhores Modelos

A tabela abaixo resume os resultados √≥timos encontrados pelo `GridSearchCV` para cada estrat√©gia de CV:

| Estrat√©gia CV | Melhor Acur√°cia M√©dia | Desvio Padr√£o (Estabilidade) | Melhores Par√¢metros Encontrados |
| :--- | :--- | :--- | :--- |
| KFold-10 | 84.13% | 0.0509 | `{'svc__C': 10, 'svc__kernel': 'rbf', 'svc__gamma': 0.001}` |
| StratifiedShuffleSplit | **84.47%** | **0.0226** | `{'svc__C': 0.1, 'svc__kernel': 'rbf', 'svc__gamma': 'scale'}` |

*(Resultados extra√≠dos da Tabela Resumo, Bloco 7 do notebook)*

### Principais Visualiza√ß√µes e Insights

* **Estabilidade do Modelo (Gr√°ficos de Linha):** O SSS (linha vermelha) demonstrou uma acur√°cia m√©dia mais est√°vel (menor vari√¢ncia) em todas as combina√ß√µes de hiperpar√¢metros testadas, em compara√ß√£o com a maior oscila√ß√£o do KFold (linha roxa).

* **Visualiza√ß√£o das Divis√µes de CV:** A an√°lise visual das parti√ß√µes demonstra como o KFold divide os dados em blocos sequenciais, enquanto o SSS amostra aleatoriamente (e de forma estratificada) o conjunto de dados em cada itera√ß√£o, fornecendo uma estimativa de generaliza√ß√£o mais robusta.

* **Justificativa do Kernel RBF (Heatmap & PCA):** O gr√°fico de An√°lise de Componentes Principais (PCA) mostrou que as classes n√£o s√£o linearmente separ√°veis. Isso justifica por que ambas as estrat√©gias de CV selecionaram o kernel **'rbf'** (n√£o linear) como a melhor op√ß√£o. O heatmap de sensibilidade (abaixo) ilustra como a acur√°cia do kernel RBF varia com `C` e `gamma`.

* **Import√¢ncia das Features (Permutation Importance):** Como o kernel 'rbf' √© n√£o linear, a *Permutation Importance* foi utilizada para avaliar o impacto de cada *feature*. A an√°lise (abaixo) mostrou que o modelo RBF baseou suas decis√µes principalmente em tr√™s atributos: `ca` (n¬∫ de vasos principais), `thal` (tipo de defeito) e `cp` (tipo de dor no peito).

## 6. üèÅ Conclus√£o

[cite_start]Embora ambas as estrat√©gias tenham alcan√ßado uma acur√°cia m√©dia semelhante (KFold 84.13% vs SSS 84.47%) [cite: 12][cite_start], o **StratifiedShuffleSplit (SSS) provou ser a metodologia superior** para este problema[cite: 14].

A principal vantagem do SSS foi sua **estabilidade**: o Desvio Padr√£o significativamente menor (0.0226) indica que seu desempenho √© mais consistente e confi√°vel entre diferentes amostras de dados, em compara√ß√£o com o KFold (0.0509).

[cite_start]Al√©m disso, a **estratifica√ß√£o** do SSS √© uma pr√°tica recomendada para dados biom√©dicos, que frequentemente s√£o desbalanceados, garantindo que o modelo seja avaliado de forma justa em ambas as classes[cite: 14, 32, 54].

## 7. üöÄ Como Executar

O projeto est√° contido no Jupyter Notebook `SVC_Doencas_Cardiacas.ipynb`.

1.  Clone este reposit√≥rio.
2.  Certifique-se de ter as bibliotecas listadas no Bloco 1 do notebook instaladas (numpy, pandas, matplotlib, seaborn, scikit-learn).
3.  Execute o notebook em um ambiente Jupyter (como Jupyter Lab, VS Code ou Google Colab).
